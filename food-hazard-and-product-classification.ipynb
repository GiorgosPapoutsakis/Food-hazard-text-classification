{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dffea24-0059-40c9-9c4e-f50973e6ed99",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "* This assignment presents a possible approach for the [Food Hazard Detection 2025 competition](https://github.com/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io).  \n",
    "* It explores data preprocessing, data augmentation, feature extraction, classification models, and hyperparameter tuning.\n",
    "\n",
    "> Giorgos Papoutsakis 8200137"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bacc75-cafe-412b-9b67-493110885de7",
   "metadata": {},
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee83887-7c48-4604-b61f-6fa3e7afec1c",
   "metadata": {},
   "source": [
    "* The first essential step needed for the model but also the whole notebook to run is importing all the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "917ee6a1-c569-41a5-9689-8fbe331e16cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0512c5-e6c1-451e-b586-14df9532fff3",
   "metadata": {},
   "source": [
    "* For text preprocessing, I will use the `nltk` library.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf7e2d16-e9b1-45d6-9f2f-4d4995aa7c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef4e44-c180-4125-bbb9-04cc1f9f77cc",
   "metadata": {},
   "source": [
    "* NLTK requires downloading some additional packages.\n",
    "* These packages will be stored in the `nltk_data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81bd935-7fc0-42c9-8e1a-297374f97b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\User\\Desktop\\Food-\n",
      "[nltk_data]     hazard-text-classification\\data/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\User\\Desktop\\Food-hazard-text-\n",
      "[nltk_data]     classification\\data/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\User\\Desktop\\Food-\n",
      "[nltk_data]     hazard-text-classification\\data/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\Desktop\\Food-hazard-text-\n",
      "[nltk_data]     classification\\data/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"NLTK_DATA\"] = os.path.join(os.getcwd(), \"data/nltk_data\")\n",
    "nltk.data.path.append(os.environ[\"NLTK_DATA\"])\n",
    "\n",
    "nltk.download('punkt', download_dir=os.environ[\"NLTK_DATA\"])\n",
    "nltk.download('punkt_tab', download_dir=os.environ[\"NLTK_DATA\"])\n",
    "nltk.download('wordnet', download_dir=os.environ[\"NLTK_DATA\"])\n",
    "nltk.download('stopwords', download_dir=os.environ[\"NLTK_DATA\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aed56a5f-7a9b-4a65-bcda-2606ee9f8256",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7d9b1-5ae6-4920-9d88-5221992b22e6",
   "metadata": {},
   "source": [
    "* In SageMaker, I had to manually install Optuna using the following command, so I kept it in the final notebook.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "902da11d-a8a9-4434-b3ee-4c1f292bc445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (1.14.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (24.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (2.0.37)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (4.67.1)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a46322c-30c9-4099-b4bd-99de6f2e855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a560a6-0286-4c47-9787-6bdc5431c5c4",
   "metadata": {},
   "source": [
    "## Datasets and Text cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b285f1c2-7b9e-47d5-81e3-3317a9fd834a",
   "metadata": {},
   "source": [
    "* The first actual step of the assignment was to download the datasets from the [GitHub repository](https://github.com/food-hazard-detection-semeval-2025/food-hazard-detection-semeval-2025.github.io/tree/main/code) and read them as DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "790b175a-88e6-410e-bbb7-130d730dd21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = pd.read_csv('data/incidents_train.csv', index_col=0)\n",
    "validation_set = pd.read_csv('data/incidents_valid.csv', index_col=0)\n",
    "test_set = pd.read_csv('data/incidents_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f78ece-3b83-45a1-8bcd-f73961424721",
   "metadata": {},
   "source": [
    "* Lets take a look in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91ef9a4a-5b13-49a7-a030-9d0f7c99d1b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>country</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>hazard-category</th>\n",
       "      <th>product-category</th>\n",
       "      <th>hazard</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>us</td>\n",
       "      <td>Recall Notification: FSIS-024-94</td>\n",
       "      <td>Case Number: 024-94   \\n            Date Opene...</td>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>smoked sausage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1994</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>us</td>\n",
       "      <td>Recall Notification: FSIS-033-94</td>\n",
       "      <td>Case Number: 033-94   \\n            Date Opene...</td>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria spp</td>\n",
       "      <td>sausage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1994</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>us</td>\n",
       "      <td>Recall Notification: FSIS-014-94</td>\n",
       "      <td>Case Number: 014-94   \\n            Date Opene...</td>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>ham slices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1994</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>us</td>\n",
       "      <td>Recall Notification: FSIS-009-94</td>\n",
       "      <td>Case Number: 009-94   \\n            Date Opene...</td>\n",
       "      <td>foreign bodies</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>plastic fragment</td>\n",
       "      <td>thermal processed pork meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1994</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>us</td>\n",
       "      <td>Recall Notification: FSIS-001-94</td>\n",
       "      <td>Case Number: 001-94   \\n            Date Opene...</td>\n",
       "      <td>foreign bodies</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>plastic fragment</td>\n",
       "      <td>chicken breast</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day country                             title  \\\n",
       "0  1994      1    7      us  Recall Notification: FSIS-024-94   \n",
       "1  1994      3   10      us  Recall Notification: FSIS-033-94   \n",
       "2  1994      3   28      us  Recall Notification: FSIS-014-94   \n",
       "3  1994      4    3      us  Recall Notification: FSIS-009-94   \n",
       "4  1994      7    1      us  Recall Notification: FSIS-001-94   \n",
       "\n",
       "                                                text hazard-category  \\\n",
       "0  Case Number: 024-94   \\n            Date Opene...      biological   \n",
       "1  Case Number: 033-94   \\n            Date Opene...      biological   \n",
       "2  Case Number: 014-94   \\n            Date Opene...      biological   \n",
       "3  Case Number: 009-94   \\n            Date Opene...  foreign bodies   \n",
       "4  Case Number: 001-94   \\n            Date Opene...  foreign bodies   \n",
       "\n",
       "               product-category                  hazard  \\\n",
       "0  meat, egg and dairy products  listeria monocytogenes   \n",
       "1  meat, egg and dairy products            listeria spp   \n",
       "2  meat, egg and dairy products  listeria monocytogenes   \n",
       "3  meat, egg and dairy products        plastic fragment   \n",
       "4  meat, egg and dairy products        plastic fragment   \n",
       "\n",
       "                       product  \n",
       "0               smoked sausage  \n",
       "1                      sausage  \n",
       "2                   ham slices  \n",
       "3  thermal processed pork meat  \n",
       "4               chicken breast  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9adba9-c531-441b-9312-b062a9cf4bbb",
   "metadata": {},
   "source": [
    "* Also, let's take a closer look at the title and text of the first row.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "290844fd-0c5e-48b5-9368-2d6519dde07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Recall Notification: FSIS-024-94'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['title'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21eae91f-c671-4684-a7f4-c5d8ff9549de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Case Number: 024-94   \\n            Date Opened: 07/01/1994   \\n            Date Closed: 09/22/1994 \\n    \\n            Recall Class:  1   \\n            Press Release (Y/N):  Y  \\n    \\n            Domestic Est. Number:  05893  P   \\n              Name:  GERHARD'S NAPA VALLEY SAUSAGE\\n    \\n            Imported Product (Y/N):  N       \\n            Foreign Estab. Number:  N/A\\n    \\n            City:  NAPA    \\n            State:  CA   \\n            Country:  USA\\n    \\n            Product:  SMOKED CHICKEN SAUSAGE\\n    \\n            Problem:  BACTERIA   \\n            Description: LISTERIA\\n    \\n            Total Pounds Recalled:  2,894   \\n            Pounds Recovered:  2,894\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6625edfd-0686-4be4-ae52-2f8379867ff6",
   "metadata": {},
   "source": [
    "* It is clear that both titles and texts need to be cleaned of all non-useful words and characters.  \n",
    "* I will create some functions to handle the cleaning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b7e64-6ed9-4395-afe0-5f250bcb8405",
   "metadata": {},
   "source": [
    "* The first function will:\n",
    "    * Convert all characters to lowercase.\n",
    "    * Remove all characters except letters.\n",
    "    * Remove all words with two or fewer characters.\n",
    "    * Remove all extra spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "667e48f2-988b-4b1d-a8bd-97aa3f5828e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www.\\S+', ' ', text) #Remove URLs\n",
    "    text = re.sub(r'[^\\w\\s]|_', ' ', text) #Remove all characters including _ exept letters and numbers\n",
    "    text = re.sub(r'\\d+', ' ', text) #Remove digits\n",
    "    text = re.sub(r'\\b\\w{1,2}\\b\\s*', '', text) #Remove all words with 2 or less characters\n",
    "    text = re.sub(r'\\s+', ' ', text) #Remove all white spaces(\\n, tabs, spaces, etc)\n",
    "    text = text.strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054f006d-93f2-49e8-a662-212c60e04da0",
   "metadata": {},
   "source": [
    "* The second function will lemmatize words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a561fc60-62ab-4b87-8d3f-1741259d8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def text_lemmatization(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token, pos=wordnet.VERB) for token in tokens] #works better if it considers it as verb\n",
    "    clean_text = \" \".join(lemmatized_tokens)\n",
    "    \n",
    "    return clean_text "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2712daae-cb20-4a7b-b188-78d9e6a4721b",
   "metadata": {},
   "source": [
    "* The third function will remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e7c5634-e290-4d0e-9c68-34dbb0168ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOP_WORDS = set(stopwords.words('english'))\n",
    "\n",
    "def stopwords_removal(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    filtered_tokens = [word for word in tokens if word not in STOP_WORDS]\n",
    "    clean_text = \" \".join(filtered_tokens)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6ace5-46d6-46dd-a965-7c1c6225ec18",
   "metadata": {},
   "source": [
    "* I will combine all functions into a single one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "595cf9f6-35c8-44a9-bab2-7909d98db7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standarization(text):\n",
    "    text = text_cleaning(text)\n",
    "    text = text_lemmatization(text)\n",
    "    text = stopwords_removal(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dec746-8c52-40ca-9d63-c90c88dd2059",
   "metadata": {},
   "source": [
    "* Finally, I will apply the function to all datasets' titles and texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1106abe8-0918-416e-9207-2fc367f7b559",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['title'] = train_set['title'].apply(custom_standarization)\n",
    "train_set['text'] = train_set['text'].apply(custom_standarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a9d969f-ed28-4c40-8676-7abecac8dc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set['title'] = validation_set['title'].apply(custom_standarization)\n",
    "validation_set['text'] = validation_set['text'].apply(custom_standarization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54b4ef8c-4024-40f4-8cc3-db5d25380821",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set['title'] = test_set['title'].apply(custom_standarization)\n",
    "test_set['text'] = test_set['text'].apply(custom_standarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ea930-c628-430f-9750-e741c79265e7",
   "metadata": {},
   "source": [
    "# Deal with Class Imbalancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd85f785-6c8c-4570-8d73-4b0b6149c821",
   "metadata": {},
   "source": [
    "* As it stated in the problem instructions, the classes for each label are highly imbalanced.\n",
    "* Let's take a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b07b73b-6e51-4f84-8a05-bfb03f5ef32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAZARD CATEGORIES\n",
      "allergens                         1854\n",
      "biological                        1741\n",
      "foreign bodies                     561\n",
      "fraud                              371\n",
      "chemical                           287\n",
      "other hazard                       134\n",
      "packaging defect                    54\n",
      "organoleptic aspects                53\n",
      "food additives and flavourings      24\n",
      "migration                            3\n",
      "Name: hazard-category, dtype: int64\n",
      "\n",
      "PRODUCT CATEGORIES\n",
      "meat, egg and dairy products                         1434\n",
      "cereals and bakery products                           671\n",
      "fruits and vegetables                                 535\n",
      "prepared dishes and snacks                            469\n",
      "seafood                                               268\n",
      "soups, broths, sauces and condiments                  264\n",
      "nuts, nut products and seeds                          262\n",
      "ices and desserts                                     222\n",
      "cocoa and cocoa preparations, coffee and tea          210\n",
      "confectionery                                         170\n",
      "non-alcoholic beverages                               134\n",
      "dietetic foods, food supplements, fortified foods     131\n",
      "herbs and spices                                      125\n",
      "alcoholic beverages                                    59\n",
      "other food product / mixed                             55\n",
      "pet feed                                               20\n",
      "fats and oils                                          19\n",
      "food additives and flavourings                          8\n",
      "honey and royal jelly                                   8\n",
      "food contact materials                                  7\n",
      "feed materials                                          6\n",
      "sugars and syrups                                       5\n",
      "Name: product-category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"HAZARD CATEGORIES\")\n",
    "print(train_set['hazard-category'].value_counts())\n",
    "print(\"\\nPRODUCT CATEGORIES\")\n",
    "print(train_set['product-category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d8734de-dadd-409c-a7b2-80c6f2fa0c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAZARD\n",
      "listeria monocytogenes                        665\n",
      "salmonella                                    621\n",
      "milk and products thereof                     588\n",
      "escherichia coli                              237\n",
      "peanuts and products thereof                  211\n",
      "                                             ... \n",
      "dioxins                                         3\n",
      "staphylococcal enterotoxin                      3\n",
      "dairy products                                  3\n",
      "sulfamethazine unauthorised                     3\n",
      "paralytic shellfish poisoning (psp) toxins      3\n",
      "Name: hazard, Length: 128, dtype: int64\n",
      "\n",
      "PRODUCT\n",
      "ice cream                                  185\n",
      "chicken based products                     138\n",
      "cakes                                       93\n",
      "ready to eat - cook meals                   79\n",
      "cookies                                     78\n",
      "                                          ... \n",
      "breakfast cereals and products therefor      1\n",
      "dried lilies                                 1\n",
      "chilled pork ribs                            1\n",
      "tortilla chips cheese                        1\n",
      "ramen noodles                                1\n",
      "Name: product, Length: 1022, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"HAZARD\")\n",
    "print(train_set['hazard'].value_counts())\n",
    "print(\"\\nPRODUCT\")\n",
    "print(train_set['product'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebb4a3d-c84f-4451-8e27-6ff2335ab029",
   "metadata": {},
   "source": [
    "* This is a serious problem especially since the evaluation metric is the F1 score.\n",
    "* If class imbalance is not addressed, the evalution score will be low.\n",
    "* To handle this, I will use data augmentation with synonyms.\n",
    "* The data augmentation idea will be:\n",
    "    * Repeatedly select rows from the least represented categories until each category reaches a certain threshold.\n",
    "    * Replace a number of words in both the title and text with synonyms.\n",
    "    * Add the new row in the training dataset.\n",
    "* As a threshold, I will use the category's median and replace 1 word from the title and 5 words from the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1277f9fd-6561-4ccb-84eb-eccc76905f50",
   "metadata": {},
   "source": [
    "* There is a special case for the product label.  \n",
    "* Its median is 2, which is really low.  \n",
    "* Later, when using cross-validation, I will get a warning that the class members are fewer than the k-folds.  \n",
    "* For these reasons, I will increase the threshold slightly. It will be 3 instead of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8cc5b6c-c08e-423b-bd14-a4aa7b198a68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "print(train_set['product'].value_counts().median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e9eb2b8-e4c0-470a-b691-cc77fa4670c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonym(word):\n",
    "    synonyms = []\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            synonyms.append(lemma.name())\n",
    "\n",
    "    return random.choice(synonyms) if synonyms else word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03c29489-82ad-4115-ab74-4c761f8f56ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augmentation_for_label(data, label):\n",
    "\n",
    "    title_changes = 1\n",
    "    text_changes = 5\n",
    "        \n",
    "    #Category for augmentation and its median\n",
    "    category_counts = data[label].value_counts()\n",
    "    threshold = category_counts.median()\n",
    "\n",
    "    # Case specific for label 'product'\n",
    "    if threshold < 3:\n",
    "        threshold = 3\n",
    "        \n",
    "    rare_categories = category_counts[category_counts <= threshold].index.tolist()\n",
    "    augmented_rows = []\n",
    "    \n",
    "    for category in rare_categories:\n",
    "        #Get threshold\n",
    "        current_count = category_counts[category]\n",
    "        needed_count = int(threshold - current_count)\n",
    "        category_data = data[data[label] == category]\n",
    "\n",
    "        random_seed = 0\n",
    "        while needed_count > 0:\n",
    "\n",
    "            random.seed(random_seed)\n",
    "            row = category_data.sample(n=1, random_state = random_seed).squeeze()\n",
    "            augmentation_details = []\n",
    "\n",
    "            #Title\n",
    "            title = row['title']\n",
    "            words_title = title.split()\n",
    "\n",
    "            words_to_change_title = title_changes\n",
    "            if len(words_title) <= words_to_change_title:\n",
    "                words_to_change_title = len(words_title)\n",
    "                \n",
    "            random_word_title = random.choice(words_title)\n",
    "            synonym_word_title = get_synonym(random_word_title)\n",
    "            augmentation_details.append((random_word_title, synonym_word_title))\n",
    "            \n",
    "            augmented_title = \" \".join([synonym_word_title if word == random_word_title else word for word in words_title])\n",
    "\n",
    "\n",
    "            #Text\n",
    "            text = row['text']\n",
    "            words_text = text.split()\n",
    "\n",
    "            words_to_change_text = text_changes\n",
    "            if len(words_text) <= words_to_change_text:\n",
    "                words_to_change_text = len(words_text)\n",
    "                \n",
    "            random_words_text = random.sample(words_text, words_to_change_text)\n",
    "            augmentation_details.extend([(word, get_synonym(word)) for word in random_words_text])\n",
    "\n",
    "            augmented_text = \" \".join([get_synonym(word) if word in random_words_text else word for word in words_text])\n",
    "\n",
    "            #Create the new columns\n",
    "            new_row = row.copy()\n",
    "            new_row['title'] = augmented_title\n",
    "            new_row['text'] = augmented_text\n",
    "            new_row[\"augmentation_details\"] = augmentation_details\n",
    "            \n",
    "            augmented_rows.append(new_row)\n",
    "            needed_count -= 1\n",
    "            random_seed += 1\n",
    "\n",
    "    #Add the new columns\n",
    "    augmented_data = pd.DataFrame(augmented_rows)\n",
    "    data = pd.concat([data, augmented_data], ignore_index=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3c3a6-97a6-403b-b589-80f5669efb43",
   "metadata": {},
   "source": [
    "* Apply the data augmentation function to all labels.\n",
    "* I will create a new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "303d45a8-0e79-4bb7-b4e4-773c534749d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_augmented = data_augmentation_for_label(\n",
    "    data=train_set,\n",
    "    label='hazard-category'\n",
    ")\n",
    "train_set_augmented = data_augmentation_for_label(\n",
    "    data=train_set_augmented,\n",
    "    label='product-category'\n",
    ")\n",
    "train_set_augmented = data_augmentation_for_label(\n",
    "    data=train_set_augmented,\n",
    "    label='hazard'\n",
    ")\n",
    "train_set_augmented = data_augmentation_for_label(\n",
    "    data=train_set_augmented,\n",
    "    label='product'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d9368e-c8df-4af1-9806-6fab3e1eada7",
   "metadata": {},
   "source": [
    "* Lets see the final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "07bbb3a6-2517-44ca-b7a8-f9dcd8d128e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAZARD CATEGORIES\n",
      "allergens                         2516\n",
      "biological                        2410\n",
      "chemical                           946\n",
      "foreign bodies                     915\n",
      "fraud                              733\n",
      "other hazard                       412\n",
      "organoleptic aspects               329\n",
      "packaging defect                   279\n",
      "food additives and flavourings     221\n",
      "migration                          210\n",
      "Name: hazard-category, dtype: int64\n",
      "\n",
      "PRODUCT CATEGORIES\n",
      "meat, egg and dairy products                         2021\n",
      "cereals and bakery products                           815\n",
      "fruits and vegetables                                 782\n",
      "prepared dishes and snacks                            599\n",
      "seafood                                               397\n",
      "soups, broths, sauces and condiments                  372\n",
      "nuts, nut products and seeds                          351\n",
      "confectionery                                         340\n",
      "dietetic foods, food supplements, fortified foods     278\n",
      "non-alcoholic beverages                               277\n",
      "cocoa and cocoa preparations, coffee and tea          275\n",
      "herbs and spices                                      269\n",
      "ices and desserts                                     248\n",
      "alcoholic beverages                                   231\n",
      "food contact materials                                228\n",
      "other food product / mixed                            226\n",
      "pet feed                                              216\n",
      "fats and oils                                         213\n",
      "honey and royal jelly                                 209\n",
      "food additives and flavourings                        208\n",
      "sugars and syrups                                     208\n",
      "feed materials                                        208\n",
      "Name: product-category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"HAZARD CATEGORIES\")\n",
    "print(train_set_augmented['hazard-category'].value_counts())\n",
    "print(\"\\nPRODUCT CATEGORIES\")\n",
    "print(train_set_augmented['product-category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4698ce4a-aef5-4afd-aa12-3b39f64c7bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAZARD\n",
      "salmonella                     902\n",
      "milk and products thereof      824\n",
      "listeria monocytogenes         818\n",
      "other                          600\n",
      "plastic fragment               325\n",
      "                              ... \n",
      "unauthorised import             17\n",
      "tampering                       17\n",
      "improper packaging              17\n",
      "celery and products thereof     17\n",
      "poor hygienic state             17\n",
      "Name: hazard, Length: 128, dtype: int64\n",
      "\n",
      "PRODUCT\n",
      "plastics             225\n",
      "pet feed             216\n",
      "ice cream            193\n",
      "feed materials       178\n",
      "honey                173\n",
      "                    ... \n",
      "semi-hard cheeses      3\n",
      "whole chicken          3\n",
      "white cheese           3\n",
      "meat broth             3\n",
      "mung bean sprouts      3\n",
      "Name: product, Length: 1022, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"HAZARD\")\n",
    "print(train_set_augmented['hazard'].value_counts())\n",
    "print(\"\\nPRODUCT\")\n",
    "print(train_set_augmented['product'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68046823-5453-4d30-9a22-3275b8064428",
   "metadata": {},
   "source": [
    "* We can see that there is still some class imbalance, but it is much better than before.  \n",
    "* Lastly, I will clean the new texts and titles once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dca7ddd7-4143-4ec9-8545-5277b9e39446",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_augmented['title'] = train_set_augmented['title'].apply(custom_standarization)\n",
    "train_set_augmented['text'] = train_set_augmented['text'].apply(custom_standarization)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02440dd-4f34-4f90-abbc-0de0d299f7f0",
   "metadata": {},
   "source": [
    "## Classification using k-fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea8219-eaad-49a1-9b96-7a9de384dbe9",
   "metadata": {},
   "source": [
    "* The approach I will follow for this multi-class text classification problem will be in two phases:\n",
    "    * The first phase is vectorizing the input title and text.\n",
    "    * The second phase is classifying the vectors.\n",
    "* Finally, I will evaluate the classification using the given function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37f40899-d033-48df-bfb4-0a50565a6cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_score(hazards_true, products_true, hazards_pred, products_pred):\n",
    "  # compute f1 for hazards:\n",
    "  f1_hazards = f1_score(\n",
    "    hazards_true,\n",
    "    hazards_pred,\n",
    "    average='macro'\n",
    "  )\n",
    "\n",
    "  # compute f1 for products:\n",
    "  f1_products = f1_score(\n",
    "    products_true[hazards_pred == hazards_true],\n",
    "    products_pred[hazards_pred == hazards_true],\n",
    "    average='macro'\n",
    "  )\n",
    "\n",
    "  return (f1_hazards + f1_products) / 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d144d253-e8a7-43cd-bb19-bd3452a84a22",
   "metadata": {},
   "source": [
    "* I will save the important columns from the training set into variables to use easily throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4339c00d-68d0-40d1-a4fa-1494ec538386",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_input = train_set_augmented[['title','text']]\n",
    "\n",
    "train_labels_hazard_category = train_set_augmented['hazard-category']\n",
    "train_labels_product_category = train_set_augmented['product-category']\n",
    "train_labels_hazard = train_set_augmented['hazard']\n",
    "train_labels_product = train_set_augmented['product']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c99b92b-62db-4d41-a6ab-b3a6d31d0924",
   "metadata": {},
   "source": [
    "* I will create two functions, one for each subtask, to try different vectorizers and classifiers.  \n",
    "* The function will use k-fold validation on the training set.  \n",
    "* The number of folds will be:\n",
    "  * 5 for the labels `hazard-category`, `product-category`, and `hazard`.  \n",
    "  * 3 for the label `product`.  \n",
    "* The reason for this difference is that the least frequent product categories have a minimum of 3 members due to the way data augmentation was implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe36122-35d3-47a8-9c9a-57ae232b1bdb",
   "metadata": {},
   "source": [
    "* The function summarizes the model's basic logic.  \n",
    "* For each label, I will use a `Pipeline` that includes a `ColumnTransformer` and a traditional vectorizer.  \n",
    "* The `ColumnTransformer` applies two vectorizers: one for the title and one for the text, then combines the outputs.  \n",
    "* The classifier then takes this combined output as input and classifies it based on the training labels.  \n",
    "* I will use `cross_val_predict` to make predictions during cross validation.  \n",
    "* I will take the predictions as pairs and evaluate them using the given evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34dda3ba-de5a-48d7-aeca-c8497fb043b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vectorizers_classifiers_subtask1(vectorizerTitle, vectorizerText, classifierHazard_category, classifierProduct_category):\n",
    "    vectorizer_title = vectorizerTitle\n",
    "    vectorizer_text = vectorizerText\n",
    "    classifier_hazard_category = classifierHazard_category\n",
    "    classifier_product_category = classifierProduct_category\n",
    "    \n",
    "    pipeline_hazard_category = Pipeline([\n",
    "        (\"vectorizer_hazard_category\", ColumnTransformer([\n",
    "            (\"title_vectorizer\", vectorizer_title, \"title\"),\n",
    "            (\"text_vectorizer\", vectorizer_text, \"text\")\n",
    "        ])),\n",
    "        (\"classifier_hazard_category\", classifier_hazard_category)\n",
    "    ])\n",
    "    \n",
    "    pipeline_product_category = Pipeline([\n",
    "        (\"vectorizer_product_category\", ColumnTransformer([\n",
    "            (\"title_vectorizer\", vectorizer_title, \"title\"),\n",
    "            (\"text_vectorizer\", vectorizer_text, \"text\")\n",
    "        ])),\n",
    "        (\"classifier_product_category\", classifier_product_category)\n",
    "    ])\n",
    "    \n",
    "    # cross-validation\n",
    "    pred_hazard_category = cross_val_predict(pipeline_hazard_category, train_set_input, train_labels_hazard_category, cv=5, n_jobs=-1)\n",
    "    pred_product_category = cross_val_predict(pipeline_product_category, train_set_input, train_labels_product_category, cv=5, n_jobs=-1)\n",
    "    \n",
    "    return compute_score(train_labels_hazard_category, train_labels_product_category, pred_hazard_category, pred_product_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "821f19a2-adef-47ea-b847-b90736a2e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_vectorizers_classifiers_subtask2(vectorizerTitle, vectorizerText, classifierHazard, classifierProduct):\n",
    "    vectorizer_title = vectorizerTitle\n",
    "    vectorizer_text = vectorizerText\n",
    "    classifier_hazard = classifierHazard\n",
    "    classifier_product = classifierProduct\n",
    "    \n",
    "    pipeline_hazard = Pipeline([\n",
    "        (\"vectorizer_hazard\", ColumnTransformer([\n",
    "            (\"title_vectorizer\", vectorizer_title, \"title\"),\n",
    "            (\"text_vectorizer\", vectorizer_text, \"text\")\n",
    "        ])),\n",
    "        (\"classifier_hazard\", classifier_hazard)\n",
    "    ])\n",
    "    \n",
    "    pipeline_product = Pipeline([\n",
    "        (\"vectorizer_product\", ColumnTransformer([\n",
    "            (\"title_vectorizer\", vectorizer_title, \"title\"),\n",
    "            (\"text_vectorizer\", vectorizer_text, \"text\")\n",
    "        ])),\n",
    "        (\"classifier_product\", classifier_product)\n",
    "    ])\n",
    "    \n",
    "    # cross-validation\n",
    "    pred_hazard = cross_val_predict(pipeline_hazard, train_set_input, train_labels_hazard, cv=5, n_jobs=-1)\n",
    "    pred_product = cross_val_predict(pipeline_product, train_set_input, train_labels_product, cv=3, n_jobs=-1)\n",
    "    \n",
    "    return compute_score(train_labels_hazard, train_labels_product, pred_hazard, pred_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f1f278-1c9a-428d-961a-dd271fd7656e",
   "metadata": {},
   "source": [
    "* I will select the vectorizers and classifiers combination that achieves the best result for each task.\n",
    "* I tried a variatey of vectorizers and classifiers. Some of thems are:\n",
    "* Vectorizers:\n",
    "  * `CountVectorizer`\n",
    "  * `TfidfVectorizer`\n",
    "* Classifiers:\n",
    "  * `LogisticRegression`\n",
    "  * `RandomForestClassifier`\n",
    "  * `LinearSVC`\n",
    "  * `SGDClassifier`\n",
    "  * `DesicionTreeClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7fc4c5-25b6-4ab5-b37e-b141d09b5017",
   "metadata": {},
   "source": [
    "* I also tried vectorizing the text and title using pre-trained embeddings from the `gensim` library.  \n",
    "* The idea was to use the embedding of each word and compute the average for each title or text before feeding it into the classifier.  \n",
    "* Unfortunately, the results were very disappointing, so I abandoned the embeddings approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd4325-3cb2-4b2f-b326-173542b6c4b8",
   "metadata": {},
   "source": [
    "* The best result was achieved using `TfidfVectorizer` and `LinearSVC` for both subtasks. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c29ff6-af77-406e-8579-31cc8764e0a0",
   "metadata": {},
   "source": [
    "* For `LinearSVC`, I didn't modify any hyperparameters and used the default settings.  \n",
    "* For `TfidfVectorizer`, I selected some hyperparameters based on experimentation and logical reasoning:\n",
    "\n",
    "  * **`ngram_range=(1,2)`**: Uses both unigrams and bigrams.  \n",
    "  * **`max_df=0.7`**: Ignores terms that appear in more than 70% of the documents.  \n",
    "  * **`min_df=2`**: Ignores terms that appear in fewer than 2 documents.  \n",
    "  * **`max_features`**: Limits the vocabulary size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "825a12dc-bd6d-4715-9646-d84279a4358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 10000)\n",
    "text_vectorizer = TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 30000)\n",
    "\n",
    "classifier_SVC = LinearSVC(random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1baf911-2ed3-4370-8d5c-015d0ca65a9e",
   "metadata": {},
   "source": [
    "* SubTask1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d05a97d5-cb37-40b8-a509-f229765e76f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337122264785322"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorizers_classifiers_subtask1(title_vectorizer, text_vectorizer, classifier_SVC, classifier_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18616deb-f82c-4ebc-ab8e-155d74a43d5c",
   "metadata": {},
   "source": [
    "* SubTask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d9650a0-5f47-46f0-9da5-2a97e9c1d558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8213583741619951"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vectorizers_classifiers_subtask2(title_vectorizer, text_vectorizer, classifier_SVC, classifier_SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9c584-0e44-43e3-8050-c9215cae9e85",
   "metadata": {},
   "source": [
    "## TfIdf & Linear SVC on Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51682287-a6e7-4a82-97dd-6d897beace8d",
   "metadata": {},
   "source": [
    "* Now that I have selected the vectorizer and classifiers, I will train them on the entire training dataset instead of a single fold each time.  \n",
    "* Then, I will evaluate them by making predictions on the validation set.\n",
    "* I will save the important columns from the validation set into variables to use easily throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3a42c739-ab83-4cd9-8918-64bf14772913",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_input = validation_set[['title','text']]\n",
    "\n",
    "validation_labels_hazard_category = validation_set['hazard-category']\n",
    "validation_labels_product_category = validation_set['product-category']\n",
    "validation_labels_hazard = validation_set['hazard']\n",
    "validation_labels_product = validation_set['product']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c7240f-d4f9-4840-bfcf-532291de4758",
   "metadata": {},
   "source": [
    "* Create vectorizer and classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3f3f60c7-0a28-4139-bc82-078d1b87b117",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = ColumnTransformer([\n",
    "        (\"title_tfidf\", TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 10000), \"title\"),\n",
    "        (\"text_tfidf\", TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 30000), \"text\")\n",
    "    ])\n",
    "\n",
    "classifier_hazard_category = LinearSVC(random_state=1234)\n",
    "classifier_product_category = LinearSVC(random_state=1234)\n",
    "classifier_hazard = LinearSVC(random_state=1234)\n",
    "classifier_product = LinearSVC(random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098738b1-e33c-4b67-bbb4-216f6d79f2f9",
   "metadata": {},
   "source": [
    "* Fit them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "843ab446-ee1b-452b-8b33-a7abec3681dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(random_state=1234)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearSVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(random_state=1234)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(random_state=1234)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_train_set_input = vectorizer.fit_transform(train_set_input)\n",
    "\n",
    "classifier_hazard_category.fit(vectorized_train_set_input, train_labels_hazard_category)\n",
    "classifier_product_category.fit(vectorized_train_set_input, train_labels_product_category)\n",
    "classifier_hazard.fit(vectorized_train_set_input, train_labels_hazard)\n",
    "classifier_product.fit(vectorized_train_set_input, train_labels_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f3abd-4f16-4395-9b24-1cd0238bfd45",
   "metadata": {},
   "source": [
    "* Predictions on Validation Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "81c57faa-94f3-490a-bd69-ec71a8768f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_valid_set_input = vectorizer.transform(validation_set_input)\n",
    "\n",
    "validation_predictions_hazard_category = classifier_hazard_category.predict(vectorized_valid_set_input)\n",
    "validation_predictions_product_category = classifier_product_category.predict(vectorized_valid_set_input)\n",
    "validation_predictions_hazard = classifier_hazard.predict(vectorized_valid_set_input)\n",
    "validation_predictions_product = classifier_product.predict(vectorized_valid_set_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c01d75-db04-4dcd-b93f-128013e70db1",
   "metadata": {},
   "source": [
    "* Evaluation for each subtask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62af421c-3252-4b18-b0e2-7b376bc4e34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE Sub-Task 1: 0.771\n",
      "SCORE Sub-Task 2: 0.454\n"
     ]
    }
   ],
   "source": [
    "print(f\"SCORE Sub-Task 1: {compute_score(validation_labels_hazard_category, validation_labels_product_category, validation_predictions_hazard_category, validation_predictions_product_category):.3f}\")\n",
    "print(f\"SCORE Sub-Task 2: {compute_score(validation_labels_hazard, validation_labels_product, validation_predictions_hazard, validation_predictions_product):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0dcfb0-309f-4ba5-8c3d-edd824143ffe",
   "metadata": {},
   "source": [
    "* The scores are lower compared to cross-validation on the training dataset.  \n",
    "* That means there is some overfitting.  \n",
    "* However, this was expected to some degree due to the way data augmentation was performed.  \n",
    "* Many rows were duplicated with only a few words changed.  \n",
    "* Nevertheless, the scores aren't too bad compared to the leaderboard. Let's see if we can improve them before the final evaluation on the test set.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5162ea4d-ae6d-4715-bafa-2cbb98f8ad79",
   "metadata": {},
   "source": [
    "## Hyper parameters search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb0d9cc-df50-4c72-93b7-9d1513b07bb8",
   "metadata": {},
   "source": [
    "* In this section, I will try to improve the scores for sub-task 1 and sub-task 2 by tuning or adding hyperparameters to the vectorizers and classifiers.  \n",
    "* However, we must keep in mind that there is already some overfitting.  \n",
    "* This raises a concern that tuning the hyperparameters might lead to even more overfitting.  \n",
    "* Ideally, I would like to try new hyperparameter values by evaluating them on the test set.  \n",
    "* However, I think this would introduce data leakage since the test set shouldn't be used until the final evaluation.  \n",
    "* Otherwise, I would be peeking at the results and making decisions based on them.  \n",
    "* For these reasons, each time I test a new hyperparameter value, I will evaluate it on the validation set.  \n",
    "* If it improves performance, I will keep it in the model. Otherwise, I will discard it, as it would only contribute to further overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848f72c1-9a4f-48c5-8414-81017988a821",
   "metadata": {},
   "source": [
    "* I will use Optuna for hyperparameter optimization and follow a three-step process:  \n",
    "  1. **Tune hyperparameters for the vectorizers**  \n",
    "  2. **Tune hyperparameters for the classifiers in subtask 1** \n",
    "  3. **Tune hyperparameters for the classifiers in subtask 2**  \n",
    "* After each step, I will evaluate the new hyperparameters on the validation set to ensure they improve performance and do not lead to excessive overfitting.  \n",
    "* The Optuna studies are not replicable. This means that rerunning the notebook will result in different Optuna results each time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6030384-4b00-4f03-b497-dd0ff5388842",
   "metadata": {},
   "source": [
    "* The first function will tune the hyperparameters for both the title and text vectorizers.  \n",
    "* The metric used will be the combined score for both subtask 1 and subtask 2.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c80592bb-49fa-4182-8f76-0b84a0b77f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_vectorizer_tuning(trial):\n",
    "\n",
    "    max_features1 = trial.suggest_int(\"max_features1\", 5000, 13000, step=1000)\n",
    "    max_features2 = trial.suggest_int(\"max_features2\", 20000, 60000, step=5000)\n",
    "    \n",
    "    ngram_choice = trial.suggest_categorical(\"ngram_range\", [1, 2, 3])\n",
    "    ngram_range = (1, ngram_choice)\n",
    "\n",
    "    max_df = trial.suggest_float(\"max_df\", 0.3, 0.8, step=0.1)\n",
    "    min_df = trial.suggest_int(\"min_df\", 1, 10)\n",
    "    \n",
    "    vectorizer_title = TfidfVectorizer(max_features=max_features1, ngram_range=ngram_range, max_df=max_df, min_df=min_df)\n",
    "    vectorizer_text = TfidfVectorizer(max_features=max_features2, ngram_range=ngram_range, max_df=max_df, min_df=min_df)\n",
    "\n",
    "    clf = LinearSVC(random_state=1234)\n",
    "\n",
    "    subtask1 = test_vectorizers_classifiers_subtask1(vectorizer_title, vectorizer_text, clf, clf)\n",
    "    subtask2 = test_vectorizers_classifiers_subtask1(vectorizer_title, vectorizer_text, clf, clf)\n",
    "\n",
    "    return subtask1 + subtask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8825d8b-8ae9-472d-8409-067c89cfa8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-13 15:56:31,019] A new study created in memory with name: no-name-d0be39c5-02fb-48d5-849d-1e76f69884ba\n",
      "[I 2025-02-13 15:57:02,357] Trial 0 finished with value: 1.8625156942891388 and parameters: {'max_features1': 5000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.7, 'min_df': 5}. Best is trial 0 with value: 1.8625156942891388.\n",
      "[I 2025-02-13 15:57:37,976] Trial 1 finished with value: 1.8710014440703078 and parameters: {'max_features1': 13000, 'max_features2': 60000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 2}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 15:57:51,349] Trial 2 finished with value: 1.8677102642825436 and parameters: {'max_features1': 12000, 'max_features2': 30000, 'ngram_range': 1, 'max_df': 0.5, 'min_df': 2}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 15:58:22,324] Trial 3 finished with value: 1.863200453937012 and parameters: {'max_features1': 9000, 'max_features2': 50000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 5}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 15:58:37,724] Trial 4 finished with value: 1.8419314320824087 and parameters: {'max_features1': 10000, 'max_features2': 30000, 'ngram_range': 1, 'max_df': 0.6000000000000001, 'min_df': 10}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 15:59:25,816] Trial 5 finished with value: 1.846402309078408 and parameters: {'max_features1': 8000, 'max_features2': 45000, 'ngram_range': 3, 'max_df': 0.5, 'min_df': 10}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 15:59:54,517] Trial 6 finished with value: 1.8551889392619394 and parameters: {'max_features1': 9000, 'max_features2': 45000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 8}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:00:25,986] Trial 7 finished with value: 1.8668010837485127 and parameters: {'max_features1': 7000, 'max_features2': 30000, 'ngram_range': 2, 'max_df': 0.3, 'min_df': 1}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:00:56,873] Trial 8 finished with value: 1.8673461241904317 and parameters: {'max_features1': 8000, 'max_features2': 30000, 'ngram_range': 2, 'max_df': 0.3, 'min_df': 3}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:01:31,074] Trial 9 finished with value: 1.8688692049582731 and parameters: {'max_features1': 11000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.8, 'min_df': 3}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:02:21,604] Trial 10 finished with value: 1.850968012077097 and parameters: {'max_features1': 13000, 'max_features2': 60000, 'ngram_range': 3, 'max_df': 0.4, 'min_df': 7}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:02:55,571] Trial 11 finished with value: 1.8690157300452563 and parameters: {'max_features1': 11000, 'max_features2': 60000, 'ngram_range': 2, 'max_df': 0.8, 'min_df': 3}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:03:29,707] Trial 12 finished with value: 1.8690157300452563 and parameters: {'max_features1': 13000, 'max_features2': 60000, 'ngram_range': 2, 'max_df': 0.8, 'min_df': 3}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:04:23,337] Trial 13 finished with value: 1.8624073171806508 and parameters: {'max_features1': 11000, 'max_features2': 40000, 'ngram_range': 3, 'max_df': 0.7, 'min_df': 1}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:04:54,749] Trial 14 finished with value: 1.864588350403402 and parameters: {'max_features1': 12000, 'max_features2': 60000, 'ngram_range': 2, 'max_df': 0.4, 'min_df': 4}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:05:08,357] Trial 15 finished with value: 1.8674699520245177 and parameters: {'max_features1': 11000, 'max_features2': 20000, 'ngram_range': 1, 'max_df': 0.7, 'min_df': 2}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:05:38,137] Trial 16 finished with value: 1.8585677407718846 and parameters: {'max_features1': 13000, 'max_features2': 50000, 'ngram_range': 2, 'max_df': 0.4, 'min_df': 6}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:06:09,948] Trial 17 finished with value: 1.86435890600373 and parameters: {'max_features1': 12000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 4}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:07:04,606] Trial 18 finished with value: 1.8613458513887626 and parameters: {'max_features1': 10000, 'max_features2': 50000, 'ngram_range': 3, 'max_df': 0.8, 'min_df': 2}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:07:17,823] Trial 19 finished with value: 1.862601373741907 and parameters: {'max_features1': 12000, 'max_features2': 40000, 'ngram_range': 1, 'max_df': 0.7, 'min_df': 4}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:07:51,172] Trial 20 finished with value: 1.8675454907585762 and parameters: {'max_features1': 5000, 'max_features2': 60000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 1}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:08:25,134] Trial 21 finished with value: 1.8690157300452563 and parameters: {'max_features1': 13000, 'max_features2': 60000, 'ngram_range': 2, 'max_df': 0.8, 'min_df': 3}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:08:58,916] Trial 22 finished with value: 1.8688692049582731 and parameters: {'max_features1': 13000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.8, 'min_df': 3}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:09:34,179] Trial 23 finished with value: 1.8692557613860958 and parameters: {'max_features1': 11000, 'max_features2': 60000, 'ngram_range': 2, 'max_df': 0.7, 'min_df': 2}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:10:08,661] Trial 24 finished with value: 1.870002523368326 and parameters: {'max_features1': 10000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.7, 'min_df': 2}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:10:42,783] Trial 25 finished with value: 1.870154630959123 and parameters: {'max_features1': 10000, 'max_features2': 50000, 'ngram_range': 2, 'max_df': 0.7, 'min_df': 2}. Best is trial 1 with value: 1.8710014440703078.\n",
      "[I 2025-02-13 16:11:16,018] Trial 26 finished with value: 1.8712761388714558 and parameters: {'max_features1': 10000, 'max_features2': 45000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:11:48,901] Trial 27 finished with value: 1.8676503565098463 and parameters: {'max_features1': 7000, 'max_features2': 45000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:12:02,587] Trial 28 finished with value: 1.8687310594023927 and parameters: {'max_features1': 8000, 'max_features2': 35000, 'ngram_range': 1, 'max_df': 0.4, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:12:55,135] Trial 29 finished with value: 1.8531765694390292 and parameters: {'max_features1': 6000, 'max_features2': 50000, 'ngram_range': 3, 'max_df': 0.5, 'min_df': 6}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:13:26,780] Trial 30 finished with value: 1.86435890600373 and parameters: {'max_features1': 10000, 'max_features2': 45000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 4}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:14:01,065] Trial 31 finished with value: 1.870002523368326 and parameters: {'max_features1': 10000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.7, 'min_df': 2}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:14:35,069] Trial 32 finished with value: 1.8701151399389544 and parameters: {'max_features1': 9000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 2}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:15:08,639] Trial 33 finished with value: 1.8700552888884843 and parameters: {'max_features1': 9000, 'max_features2': 50000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 2}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:15:39,589] Trial 34 finished with value: 1.8629883234226874 and parameters: {'max_features1': 9000, 'max_features2': 50000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 5}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:15:53,443] Trial 35 finished with value: 1.8683175425336773 and parameters: {'max_features1': 8000, 'max_features2': 45000, 'ngram_range': 1, 'max_df': 0.6000000000000001, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:16:27,482] Trial 36 finished with value: 1.869775487201795 and parameters: {'max_features1': 9000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 2}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:16:56,167] Trial 37 finished with value: 1.8550677986463344 and parameters: {'max_features1': 7000, 'max_features2': 35000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 9}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:17:26,831] Trial 38 finished with value: 1.8629883234226874 and parameters: {'max_features1': 10000, 'max_features2': 45000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 5}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:17:56,833] Trial 39 finished with value: 1.8690411373581808 and parameters: {'max_features1': 9000, 'max_features2': 20000, 'ngram_range': 2, 'max_df': 0.4, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:18:48,541] Trial 40 finished with value: 1.8585228608333884 and parameters: {'max_features1': 8000, 'max_features2': 40000, 'ngram_range': 3, 'max_df': 0.5, 'min_df': 3}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:19:22,606] Trial 41 finished with value: 1.8700552888884843 and parameters: {'max_features1': 9000, 'max_features2': 50000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 2}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:19:56,607] Trial 42 finished with value: 1.8701151399389544 and parameters: {'max_features1': 9000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 2}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:20:30,410] Trial 43 finished with value: 1.8698362106627389 and parameters: {'max_features1': 8000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.6000000000000001, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:21:04,841] Trial 44 finished with value: 1.8703070748476103 and parameters: {'max_features1': 10000, 'max_features2': 55000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 2}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:21:38,499] Trial 45 finished with value: 1.8688132724712947 and parameters: {'max_features1': 10000, 'max_features2': 50000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 3}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:22:12,867] Trial 46 finished with value: 1.8712529434890794 and parameters: {'max_features1': 12000, 'max_features2': 45000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:22:26,564] Trial 47 finished with value: 1.8687310594023927 and parameters: {'max_features1': 12000, 'max_features2': 45000, 'ngram_range': 1, 'max_df': 0.4, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:22:55,588] Trial 48 finished with value: 1.8551889392619394 and parameters: {'max_features1': 11000, 'max_features2': 35000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 8}. Best is trial 26 with value: 1.8712761388714558.\n",
      "[I 2025-02-13 16:23:49,624] Trial 49 finished with value: 1.8624630697478755 and parameters: {'max_features1': 12000, 'max_features2': 45000, 'ngram_range': 3, 'max_df': 0.3, 'min_df': 1}. Best is trial 26 with value: 1.8712761388714558.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'max_features1': 10000, 'max_features2': 45000, 'ngram_range': 2, 'max_df': 0.5, 'min_df': 1}\n"
     ]
    }
   ],
   "source": [
    "study1 = optuna.create_study(direction=\"maximize\")\n",
    "study1.optimize(objective_vectorizer_tuning, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study1.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e58edee-19e7-4a2c-b98e-d5ef8afabc76",
   "metadata": {},
   "source": [
    "* I will now use the tuned hyperparameters for evaluation on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa8af937-5941-40c0-ac81-d5cbe250f971",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_vectorizer = ColumnTransformer([\n",
    "        (\"title_tfidf\", TfidfVectorizer(max_features = 10000, ngram_range=(1,2), max_df=0.5, min_df=1), \"title\"),\n",
    "        (\"text_tfidf\", TfidfVectorizer(max_features = 45000, ngram_range=(1,2), max_df=0.5, min_df=1), \"text\")\n",
    "    ])\n",
    "\n",
    "tuned_vectorized_train_set_input = tuned_vectorizer.fit_transform(train_set_input)\n",
    "tuned_vectorized_valid_set_input = tuned_vectorizer.transform(validation_set_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56f4326e-dc69-46f9-8c4f-1f5452f24ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE Sub-Task 1: 0.775\n",
      "SCORE Sub-Task 2: 0.443\n"
     ]
    }
   ],
   "source": [
    "#Create\n",
    "classifier_hazard_category = LinearSVC(random_state=1234)\n",
    "classifier_product_category = LinearSVC(random_state=1234)\n",
    "classifier_hazard = LinearSVC(random_state=1234)\n",
    "classifier_product = LinearSVC(random_state=1234)\n",
    "\n",
    "#Fit\n",
    "classifier_hazard_category.fit(tuned_vectorized_train_set_input, train_labels_hazard_category)\n",
    "classifier_product_category.fit(tuned_vectorized_train_set_input, train_labels_product_category)\n",
    "classifier_hazard.fit(tuned_vectorized_train_set_input, train_labels_hazard)\n",
    "classifier_product.fit(tuned_vectorized_train_set_input, train_labels_product)\n",
    "\n",
    "#Predict\n",
    "validation_predictions_hazard_category = classifier_hazard_category.predict(tuned_vectorized_valid_set_input)\n",
    "validation_predictions_product_category = classifier_product_category.predict(tuned_vectorized_valid_set_input)\n",
    "validation_predictions_hazard = classifier_hazard.predict(tuned_vectorized_valid_set_input)\n",
    "validation_predictions_product = classifier_product.predict(tuned_vectorized_valid_set_input)\n",
    "\n",
    "#Evaluate\n",
    "print(f\"SCORE Sub-Task 1: {compute_score(validation_labels_hazard_category, validation_labels_product_category, validation_predictions_hazard_category, validation_predictions_product_category):.3f}\")\n",
    "print(f\"SCORE Sub-Task 2: {compute_score(validation_labels_hazard, validation_labels_product, validation_predictions_hazard, validation_predictions_product):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b82219c-8201-419c-9640-70d42c45fd3a",
   "metadata": {},
   "source": [
    "* There is a slight increase in the score for sub-task 1 and a slight decrease in the score for sub-task 2.  \n",
    "* Since the decrease is larger than the increase, I will choose not to use the tuned vectorizer parameters and will keep the untuned ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d250a81-6b6b-4d40-9670-c04bc17a5710",
   "metadata": {},
   "source": [
    "* This function will tune the classifier's hyperparameters for subtask 1.  \n",
    "* Hyperparameters to tune: \n",
    "  * **C**: Controls the regularization strength.  \n",
    "  * **loss**: Defines the loss function used by the model.  \n",
    "* The vectorizers will use the untuned parameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f303b12-a970-434c-8bc4-700693a4b8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_classifiers_tuning_task1(trial):\n",
    "\n",
    "    vectorizer_title = TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 10000)\n",
    "    vectorizer_text = TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 30000)\n",
    "\n",
    "    C1 = trial.suggest_float(\"C1\", 0.01, 10.0, log=True)\n",
    "    C2 = trial.suggest_float(\"C2\", 0.01, 10.0, log=True)\n",
    "    \n",
    "    loss1 = trial.suggest_categorical(\"loss1\", [\"hinge\", \"squared_hinge\"])\n",
    "    loss2 = trial.suggest_categorical(\"loss2\", [\"hinge\", \"squared_hinge\"])\n",
    "\n",
    "    # high max iters in order not to fail to converge\n",
    "    clf1 = LinearSVC(C=C1, loss=loss1, max_iter=10000, random_state=1234)\n",
    "    clf2 = LinearSVC(C=C2, loss=loss2, max_iter=10000, random_state=1234)\n",
    "\n",
    "    return test_vectorizers_classifiers_subtask1(vectorizer_title, vectorizer_text, clf1, clf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "afd7e3f5-3611-4221-b4b5-bfebc77817e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-13 16:25:55,763] A new study created in memory with name: no-name-6ec0ff7e-0dfb-44ef-923a-463ad4cff7dc\n",
      "[I 2025-02-13 16:26:11,802] Trial 0 finished with value: 0.9343754612868326 and parameters: {'C1': 2.0977590496642193, 'C2': 0.5385824296479859, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:26:27,241] Trial 1 finished with value: 0.8819138483284339 and parameters: {'C1': 2.4427638180692663, 'C2': 0.020995705524877985, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:26:45,173] Trial 2 finished with value: 0.8772865993715859 and parameters: {'C1': 0.860562568566405, 'C2': 0.010535471788045191, 'loss1': 'squared_hinge', 'loss2': 'hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:27:01,433] Trial 3 finished with value: 0.8578348470383523 and parameters: {'C1': 0.01138757894393367, 'C2': 0.8987699820921236, 'loss1': 'hinge', 'loss2': 'squared_hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:27:19,762] Trial 4 finished with value: 0.8884383387094648 and parameters: {'C1': 0.07310923462050474, 'C2': 0.12039891243316926, 'loss1': 'hinge', 'loss2': 'squared_hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:28:35,959] Trial 5 finished with value: 0.928792060515923 and parameters: {'C1': 1.26175766766595, 'C2': 8.356891780654529, 'loss1': 'hinge', 'loss2': 'hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:28:50,164] Trial 6 finished with value: 0.9195330830147403 and parameters: {'C1': 0.14442001030093252, 'C2': 0.19734416383266945, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:29:41,033] Trial 7 finished with value: 0.9309106982939134 and parameters: {'C1': 0.7456808208367169, 'C2': 7.310824522949725, 'loss1': 'squared_hinge', 'loss2': 'hinge'}. Best is trial 0 with value: 0.9343754612868326.\n",
      "[I 2025-02-13 16:29:58,005] Trial 8 finished with value: 0.9344303856792648 and parameters: {'C1': 1.24373426444012, 'C2': 1.5487045043446899, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 8 with value: 0.9344303856792648.\n",
      "[I 2025-02-13 16:30:13,593] Trial 9 finished with value: 0.8670200023094791 and parameters: {'C1': 0.02465635097391158, 'C2': 0.1545437501205673, 'loss1': 'hinge', 'loss2': 'squared_hinge'}. Best is trial 8 with value: 0.9344303856792648.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-02-13 16:31:13,804] Trial 10 finished with value: 0.9334271833927255 and parameters: {'C1': 9.39128057230716, 'C2': 1.6750034690789963, 'loss1': 'squared_hinge', 'loss2': 'hinge'}. Best is trial 8 with value: 0.9344303856792648.\n",
      "[I 2025-02-13 16:31:32,042] Trial 11 finished with value: 0.9344867556518285 and parameters: {'C1': 5.296454360202621, 'C2': 1.1697368485712403, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:31:52,957] Trial 12 finished with value: 0.9338949355635815 and parameters: {'C1': 8.849049453411643, 'C2': 2.0332696538315966, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:32:11,798] Trial 13 finished with value: 0.934277259415788 and parameters: {'C1': 3.8167700078440143, 'C2': 1.8733085890735424, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:32:30,722] Trial 14 finished with value: 0.927252591196563 and parameters: {'C1': 0.3139259878088879, 'C2': 3.8218712838204345, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:32:45,695] Trial 15 finished with value: 0.9306580393843625 and parameters: {'C1': 0.39922390825165865, 'C2': 0.5565994116242868, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:33:02,049] Trial 16 finished with value: 0.9181819135813387 and parameters: {'C1': 4.553012243138575, 'C2': 0.07642574213516219, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:33:17,567] Trial 17 finished with value: 0.9341925737120742 and parameters: {'C1': 1.6970422639933356, 'C2': 0.3711041328496573, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:34:26,925] Trial 18 finished with value: 0.9339359661363952 and parameters: {'C1': 5.048243189234608, 'C2': 1.023225547050291, 'loss1': 'hinge', 'loss2': 'hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:34:45,903] Trial 19 finished with value: 0.9297392704660243 and parameters: {'C1': 0.4108006891080901, 'C2': 3.673640796780792, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:35:00,208] Trial 20 finished with value: 0.9049655529997513 and parameters: {'C1': 0.17218563993317096, 'C2': 0.05943047575237499, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 11 with value: 0.9344867556518285.\n",
      "[I 2025-02-13 16:35:16,895] Trial 21 finished with value: 0.9347258055240517 and parameters: {'C1': 2.583588252229589, 'C2': 0.6545971815026282, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:35:34,312] Trial 22 finished with value: 0.9344959995456961 and parameters: {'C1': 3.4829628292614685, 'C2': 1.0212017885495321, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:35:50,406] Trial 23 finished with value: 0.9323723124275609 and parameters: {'C1': 3.0766573971733115, 'C2': 0.2831251453428927, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:36:08,067] Trial 24 finished with value: 0.9343722408180757 and parameters: {'C1': 4.895716379026882, 'C2': 0.760850841274696, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:36:30,687] Trial 25 finished with value: 0.9330276724635348 and parameters: {'C1': 7.207073334496051, 'C2': 3.8557003674246517, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:37:21,703] Trial 26 finished with value: 0.9269965784296315 and parameters: {'C1': 2.7171798785450383, 'C2': 0.41981110412683664, 'loss1': 'hinge', 'loss2': 'hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:37:40,281] Trial 27 finished with value: 0.933085508945234 and parameters: {'C1': 0.8980951153709771, 'C2': 2.845889383875881, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:37:58,758] Trial 28 finished with value: 0.9342635540341149 and parameters: {'C1': 6.151041385170039, 'C2': 1.0718384405281407, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:38:14,433] Trial 29 finished with value: 0.9342237708910979 and parameters: {'C1': 1.5637023989390968, 'C2': 0.5395577670641623, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:38:30,005] Trial 30 finished with value: 0.9321162803601919 and parameters: {'C1': 2.256743881776927, 'C2': 0.2603351253703334, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:38:46,599] Trial 31 finished with value: 0.9343604872770133 and parameters: {'C1': 1.3639076376453994, 'C2': 1.3050193365094693, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:39:03,236] Trial 32 finished with value: 0.9346195344463792 and parameters: {'C1': 2.8367692507321283, 'C2': 0.7351422336511051, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:39:19,965] Trial 33 finished with value: 0.9344167798184604 and parameters: {'C1': 3.0346664499093663, 'C2': 0.7802706707920225, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:39:35,504] Trial 34 finished with value: 0.9331676039893064 and parameters: {'C1': 0.6509255359204345, 'C2': 0.6088900768236654, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:39:54,149] Trial 35 finished with value: 0.9339537496259522 and parameters: {'C1': 2.1074655277655165, 'C2': 2.6571999681760996, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:40:50,085] Trial 36 finished with value: 0.9262744431880832 and parameters: {'C1': 3.3164677065015704, 'C2': 0.3802773882629999, 'loss1': 'hinge', 'loss2': 'hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:41:08,703] Trial 37 finished with value: 0.9344068200031317 and parameters: {'C1': 6.686038834880038, 'C2': 0.8708865238531224, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:41:42,030] Trial 38 finished with value: 0.8883691112290819 and parameters: {'C1': 1.0960152270452206, 'C2': 0.026843520648026056, 'loss1': 'hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:42:39,656] Trial 39 finished with value: 0.9318797112772608 and parameters: {'C1': 1.853646975701417, 'C2': 5.039591961770248, 'loss1': 'squared_hinge', 'loss2': 'hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:42:53,868] Trial 40 finished with value: 0.9081214207039512 and parameters: {'C1': 0.052666142316265326, 'C2': 0.21390784755962622, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:43:12,379] Trial 41 finished with value: 0.9346681508049537 and parameters: {'C1': 4.078667006942234, 'C2': 1.3774413096053502, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:43:32,821] Trial 42 finished with value: 0.9343615361873927 and parameters: {'C1': 9.894421965886878, 'C2': 1.2724048697258132, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 21 with value: 0.9347258055240517.\n",
      "[I 2025-02-13 16:43:49,923] Trial 43 finished with value: 0.9347513492672905 and parameters: {'C1': 3.811480273361187, 'C2': 0.6717686732052814, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 43 with value: 0.9347513492672905.\n",
      "[I 2025-02-13 16:44:07,074] Trial 44 finished with value: 0.9345817151360305 and parameters: {'C1': 3.525573989168812, 'C2': 0.675512422262055, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 43 with value: 0.9347513492672905.\n",
      "[I 2025-02-13 16:44:22,090] Trial 45 finished with value: 0.9329364857944498 and parameters: {'C1': 0.594629961968817, 'C2': 0.45005013790339304, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 43 with value: 0.9347513492672905.\n",
      "[I 2025-02-13 16:44:38,478] Trial 46 finished with value: 0.9348781482086148 and parameters: {'C1': 2.361742992708202, 'C2': 0.6397958094930469, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 46 with value: 0.9348781482086148.\n",
      "[I 2025-02-13 16:45:14,004] Trial 47 finished with value: 0.9232160353137089 and parameters: {'C1': 2.2992274614336234, 'C2': 0.10841162381251643, 'loss1': 'hinge', 'loss2': 'squared_hinge'}. Best is trial 46 with value: 0.9348781482086148.\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "[I 2025-02-13 16:46:15,292] Trial 48 finished with value: 0.9330132856147093 and parameters: {'C1': 0.8635087523084946, 'C2': 1.5285507965493978, 'loss1': 'squared_hinge', 'loss2': 'hinge'}. Best is trial 46 with value: 0.9348781482086148.\n",
      "[I 2025-02-13 16:46:33,062] Trial 49 finished with value: 0.9337063024555151 and parameters: {'C1': 1.1465745818114335, 'C2': 2.3001175196464327, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}. Best is trial 46 with value: 0.9348781482086148.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C1': 2.361742992708202, 'C2': 0.6397958094930469, 'loss1': 'squared_hinge', 'loss2': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "study2 = optuna.create_study(direction=\"maximize\")\n",
    "study2.optimize(objective_classifiers_tuning_task1, n_trials=50)\n",
    "\n",
    "print(\"Best hyperparameters:\", study2.best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a53ec0-ff5f-4c39-b6c2-55cf0e8c1123",
   "metadata": {},
   "source": [
    "* I will now use the tuned hyperparameters for evaluation on the validation set.\n",
    "* The `vectorized_train_set_input` and `vectorized_valid_set_input` are results from the untuned vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e736232c-b363-40cc-86ce-b8239dfa6b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE Sub-Task 1: 0.769\n"
     ]
    }
   ],
   "source": [
    "#Create\n",
    "tuned_classifier_hazard_category = LinearSVC(C=2.3617, loss= 'squared_hinge', random_state=1234, max_iter=10000)\n",
    "tuned_classifier_product_category = LinearSVC(C=0.6397, loss= 'squared_hinge', random_state=1234, max_iter=10000)\n",
    "\n",
    "#Fit\n",
    "tuned_classifier_hazard_category.fit(vectorized_train_set_input, train_labels_hazard_category)\n",
    "tuned_classifier_product_category.fit(vectorized_train_set_input, train_labels_product_category)\n",
    "\n",
    "#Predict\n",
    "validation_predictions_hazard_category = tuned_classifier_hazard_category.predict(vectorized_valid_set_input)\n",
    "validation_predictions_product_category = tuned_classifier_product_category.predict(vectorized_valid_set_input)\n",
    "\n",
    "#Evaluate\n",
    "print(f\"SCORE Sub-Task 1: {compute_score(validation_labels_hazard_category, validation_labels_product_category, validation_predictions_hazard_category, validation_predictions_product_category):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b6e852-8158-4ef7-90b1-a112de527cfb",
   "metadata": {},
   "source": [
    "* Once again, the results got slightly worse, indicating more overfitting.  \n",
    "* So, I will not use the tuned hyperparameters in the classifiers.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db83e69e-5704-4c9e-9306-35a3379dc76d",
   "metadata": {},
   "source": [
    "* The third function will tune the classifier's hyperparameters for subtask 3.  \n",
    "* I will use the untuned parameters for the vectorizers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "501aab8c-c90a-418a-857a-58e89c2d9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_classifiers_tuning_task2(trial):\n",
    "\n",
    "    vectorizer_title = TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 10000)\n",
    "    vectorizer_text = TfidfVectorizer(ngram_range=(1,2), max_df=0.7, min_df=2, max_features = 30000)\n",
    "\n",
    "    C3 = trial.suggest_float(\"C3\", 0.01, 10.0, log=True)\n",
    "    C4 = trial.suggest_float(\"C4\", 0.01, 10.0, log=True)\n",
    "    \n",
    "    loss3 = trial.suggest_categorical(\"loss3\", [\"hinge\", \"squared_hinge\"])\n",
    "    loss4 = trial.suggest_categorical(\"loss4\", [\"hinge\", \"squared_hinge\"])\n",
    "\n",
    "    # high max iters in order not to fail to converge\n",
    "    clf3 = LinearSVC(C=C3, loss=loss3, max_iter=10000, random_state=1234)\n",
    "    clf4 = LinearSVC(C=C4, loss=loss4, max_iter=10000, random_state=1234)\n",
    "\n",
    "    return test_vectorizers_classifiers_subtask2(vectorizer_title, vectorizer_text, clf3, clf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898693ba-d3ad-4387-b53e-a8335b87d1c1",
   "metadata": {},
   "source": [
    "* This study was significantly slower compared to the other two, so I ran 30 trials instead of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe43c28a-be31-4bfd-be68-c4c768c7a756",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-11 20:32:07,939] A new study created in memory with name: no-name-c70ad19e-5e02-4c68-b3d3-392860a57cad\n",
      "[I 2025-02-11 20:34:08,161] Trial 0 finished with value: 0.8199202410932087 and parameters: {'C3': 1.3248506587681272, 'C4': 0.9146762733538936, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 0 with value: 0.8199202410932087.\n",
      "[I 2025-02-11 20:37:03,115] Trial 1 finished with value: 0.8067905428950513 and parameters: {'C3': 6.605941546175378, 'C4': 0.11282682041251339, 'loss3': 'hinge', 'loss4': 'hinge'}. Best is trial 0 with value: 0.8199202410932087.\n",
      "[I 2025-02-11 20:38:30,474] Trial 2 finished with value: 0.7147911538976564 and parameters: {'C3': 1.2402529659862864, 'C4': 0.012850149527030022, 'loss3': 'squared_hinge', 'loss4': 'squared_hinge'}. Best is trial 0 with value: 0.8199202410932087.\n",
      "[I 2025-02-11 20:39:58,231] Trial 3 finished with value: 0.8069535936239078 and parameters: {'C3': 9.811828544166803, 'C4': 0.08002787746125997, 'loss3': 'squared_hinge', 'loss4': 'squared_hinge'}. Best is trial 0 with value: 0.8199202410932087.\n",
      "[I 2025-02-11 20:41:41,763] Trial 4 finished with value: 0.7565022310004627 and parameters: {'C3': 0.018004559158473554, 'C4': 5.853468971203055, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 0 with value: 0.8199202410932087.\n",
      "[I 2025-02-11 20:43:14,529] Trial 5 finished with value: 0.7672023945120007 and parameters: {'C3': 0.04537714170087791, 'C4': 1.1004117826553284, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 0 with value: 0.8199202410932087.\n",
      "[I 2025-02-11 20:44:40,381] Trial 6 finished with value: 0.7522056225180771 and parameters: {'C3': 0.02492977208751412, 'C4': 0.17289094716561068, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 0 with value: 0.8199202410932087.\n",
      "[I 2025-02-11 20:46:47,079] Trial 7 finished with value: 0.8218865244589726 and parameters: {'C3': 3.2864700353286187, 'C4': 2.312267631251525, 'loss3': 'squared_hinge', 'loss4': 'hinge'}. Best is trial 7 with value: 0.8218865244589726.\n",
      "[I 2025-02-11 20:49:05,160] Trial 8 finished with value: 0.8238222448618311 and parameters: {'C3': 3.716013945691863, 'C4': 9.408636552187366, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 20:50:59,644] Trial 9 finished with value: 0.8227627674387199 and parameters: {'C3': 4.5195678809204285, 'C4': 0.7242033003659989, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 20:52:59,123] Trial 10 finished with value: 0.8082929838714896 and parameters: {'C3': 0.15913203716863786, 'C4': 9.87452385381392, 'loss3': 'squared_hinge', 'loss4': 'hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 20:54:47,044] Trial 11 finished with value: 0.8108474253794543 and parameters: {'C3': 0.5462331147643027, 'C4': 0.39623650996247617, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 20:56:45,977] Trial 12 finished with value: 0.8229415430637398 and parameters: {'C3': 2.6268938606598513, 'C4': 2.542623830199974, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 20:58:57,879] Trial 13 finished with value: 0.8222373631359206 and parameters: {'C3': 1.7773636154727115, 'C4': 4.050944782084171, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 21:01:15,166] Trial 14 finished with value: 0.801559796754497 and parameters: {'C3': 0.28611758752887106, 'C4': 2.7069389276818487, 'loss3': 'hinge', 'loss4': 'hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 21:03:24,790] Trial 15 finished with value: 0.8134757838538667 and parameters: {'C3': 0.5788529128551254, 'C4': 9.508141859296538, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 21:05:00,350] Trial 16 finished with value: 0.7840020916767243 and parameters: {'C3': 0.09614142143555061, 'C4': 2.1083591652234137, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 21:06:58,624] Trial 17 finished with value: 0.7815581908510632 and parameters: {'C3': 2.6210663199910096, 'C4': 0.03591726846241462, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 21:08:56,691] Trial 18 finished with value: 0.8118023551345879 and parameters: {'C3': 0.9814404959599075, 'C4': 0.39957653580737257, 'loss3': 'squared_hinge', 'loss4': 'hinge'}. Best is trial 8 with value: 0.8238222448618311.\n",
      "[I 2025-02-11 21:11:05,062] Trial 19 finished with value: 0.8249974467929171 and parameters: {'C3': 9.551176444912237, 'C4': 4.597265950166175, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:13:13,265] Trial 20 finished with value: 0.824762809693004 and parameters: {'C3': 9.615438131026123, 'C4': 5.321527953897735, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:15:23,920] Trial 21 finished with value: 0.824913021458944 and parameters: {'C3': 9.865787707866955, 'C4': 5.054695332876625, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:17:31,698] Trial 22 finished with value: 0.8249788813522401 and parameters: {'C3': 9.76403032065044, 'C4': 4.262666224146556, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:19:30,955] Trial 23 finished with value: 0.8240284380206953 and parameters: {'C3': 5.8437480121165, 'C4': 1.2666910761261143, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:21:38,259] Trial 24 finished with value: 0.8249788813522401 and parameters: {'C3': 9.773821968751172, 'C4': 4.3246614374360055, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:23:38,999] Trial 25 finished with value: 0.8242520857796922 and parameters: {'C3': 5.867425836876763, 'C4': 1.653943573976435, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:25:45,335] Trial 26 finished with value: 0.8224164113343424 and parameters: {'C3': 2.3127384925758703, 'C4': 3.4606095876448295, 'loss3': 'squared_hinge', 'loss4': 'hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:27:40,128] Trial 27 finished with value: 0.8231981517523556 and parameters: {'C3': 5.181370111324496, 'C4': 0.6223059194377432, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:29:10,135] Trial 28 finished with value: 0.7541301760731376 and parameters: {'C3': 0.011270670793992684, 'C4': 1.606577720428509, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n",
      "[I 2025-02-11 21:31:01,859] Trial 29 finished with value: 0.818984064696926 and parameters: {'C3': 1.1060278234046022, 'C4': 0.863315966488525, 'loss3': 'hinge', 'loss4': 'squared_hinge'}. Best is trial 19 with value: 0.8249974467929171.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C3': 9.551176444912237, 'C4': 4.597265950166175, 'loss3': 'hinge', 'loss4': 'squared_hinge'}\n"
     ]
    }
   ],
   "source": [
    "study3 = optuna.create_study(direction=\"maximize\")\n",
    "study3.optimize(objective_classifiers_tuning_task2, n_trials=30)\n",
    "\n",
    "print(\"Best hyperparameters:\", study3.best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "18c88001-00e0-4d40-be4f-681803f96cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE Sub-Task 2: 0.458\n"
     ]
    }
   ],
   "source": [
    "#Create\n",
    "tuned_classifier_hazard = LinearSVC(C=9.5511, loss= 'hinge', random_state=1234, max_iter=10000)\n",
    "tuned_classifier_product = LinearSVC(C=4.5972, loss= 'squared_hinge', random_state=1234, max_iter=10000)\n",
    "\n",
    "#Fit\n",
    "tuned_classifier_hazard.fit(vectorized_train_set_input, train_labels_hazard)\n",
    "tuned_classifier_product.fit(vectorized_train_set_input, train_labels_product)\n",
    "\n",
    "#Predict\n",
    "validation_predictions_hazard = tuned_classifier_hazard.predict(vectorized_valid_set_input)\n",
    "validation_predictions_product = tuned_classifier_product.predict(vectorized_valid_set_input)\n",
    "\n",
    "#Evaluate\n",
    "print(f\"SCORE Sub-Task 2: {compute_score(validation_labels_hazard, validation_labels_product, validation_predictions_hazard, validation_predictions_product):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80ee15b-2702-480d-9a5e-6ed78116c1ee",
   "metadata": {},
   "source": [
    "* Finally, there is a clear improvement in the validation set.  \n",
    "* Therefore, I will keep the tuned hyperparameters for the hazard and product classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba8cc35-1ec1-4526-b723-794ec9c87ac8",
   "metadata": {},
   "source": [
    "## Final Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986a6fb7-6bbc-4570-899e-744a1ef8e21c",
   "metadata": {},
   "source": [
    "* It's time for the final evaluation.  \n",
    "* I will evaluate the entire model on both the validation and test sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "52793aa5-42be-4611-afdc-1b685fd2c3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_input = test_set[['title','text']]\n",
    "\n",
    "test_labels_hazard_category = test_set['hazard-category']\n",
    "test_labels_product_category = test_set['product-category']\n",
    "test_labels_hazard = test_set['hazard']\n",
    "test_labels_product = test_set['product']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d9141b-c40e-4a28-9554-5d03b6530906",
   "metadata": {},
   "source": [
    "* Create the ColumnTransformer and classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c8f675ba-1acd-46b6-b21c-02f93092c1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_vectorizer = ColumnTransformer([\n",
    "        (\"title_tfidf\", TfidfVectorizer(max_features = 10000, ngram_range=(1,2), max_df=0.7, min_df=2), \"title\"),\n",
    "        (\"text_tfidf\", TfidfVectorizer(max_features = 30000, ngram_range=(1,2), max_df=0.7, min_df=2), \"text\")\n",
    "    ])\n",
    "\n",
    "final_classifier_hazard_category = LinearSVC(random_state=1234)\n",
    "final_classifier_product_category = LinearSVC(random_state=1234)\n",
    "final_classifier_hazard = LinearSVC(C=9.5511, loss= 'hinge', random_state=1234, max_iter=10000)\n",
    "final_classifier_product = LinearSVC(C=4.5972, loss= 'squared_hinge', random_state=1234, max_iter=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace60472-3bfd-40dc-a9c5-971127e92d48",
   "metadata": {},
   "source": [
    "* Fit them with the entire training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3fc61cec-9e5a-45ba-b883-abe21c2530a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC(C=4.5972, max_iter=10000, random_state=1234)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LinearSVC</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.svm.LinearSVC.html\">?<span>Documentation for LinearSVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LinearSVC(C=4.5972, max_iter=10000, random_state=1234)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LinearSVC(C=4.5972, max_iter=10000, random_state=1234)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_vectorized_train_set_input = final_vectorizer.fit_transform(train_set_input)\n",
    "\n",
    "final_classifier_hazard_category.fit(final_vectorized_train_set_input, train_labels_hazard_category)\n",
    "final_classifier_product_category.fit(final_vectorized_train_set_input, train_labels_product_category)\n",
    "final_classifier_hazard.fit(final_vectorized_train_set_input, train_labels_hazard)\n",
    "final_classifier_product.fit(final_vectorized_train_set_input, train_labels_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82971afa-7272-44a3-8fd6-1d5359cc945e",
   "metadata": {},
   "source": [
    "* Predictions and Evaluation on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d53c3714-8fb3-4168-b2a6-443b11f3b433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE Sub-Task 1: 0.771\n",
      "SCORE Sub-Task 2: 0.458\n"
     ]
    }
   ],
   "source": [
    "final_vectorized_validation_set_input = final_vectorizer.transform(validation_set_input)\n",
    "\n",
    "validation_predictions_hazard_category = final_classifier_hazard_category.predict(final_vectorized_validation_set_input)\n",
    "validation_predictions_product_category = final_classifier_product_category.predict(final_vectorized_validation_set_input)\n",
    "validation_predictions_hazard = final_classifier_hazard.predict(final_vectorized_validation_set_input)\n",
    "validation_predictions_product = final_classifier_product.predict(final_vectorized_validation_set_input)\n",
    "\n",
    "print(f\"SCORE Sub-Task 1: {compute_score(validation_labels_hazard_category, validation_labels_product_category, validation_predictions_hazard_category, validation_predictions_product_category):.3f}\")\n",
    "print(f\"SCORE Sub-Task 2: {compute_score(validation_labels_hazard, validation_labels_product, validation_predictions_hazard, validation_predictions_product):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297e9c9c-2c4a-4010-8881-3eb2bfdd6613",
   "metadata": {},
   "source": [
    "* Predictions and Evaluation on the unseen testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7053a205-7a1b-43ff-b010-62b85cf4b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE Sub-Task 1: 0.727\n",
      "SCORE Sub-Task 2: 0.419\n"
     ]
    }
   ],
   "source": [
    "final_vectorized_test_set_input = final_vectorizer.transform(test_set_input)\n",
    "\n",
    "test_predictions_hazard_category = final_classifier_hazard_category.predict(final_vectorized_test_set_input)\n",
    "test_predictions_product_category = final_classifier_product_category.predict(final_vectorized_test_set_input)\n",
    "test_predictions_hazard = final_classifier_hazard.predict(final_vectorized_test_set_input)\n",
    "test_predictions_product = final_classifier_product.predict(final_vectorized_test_set_input)\n",
    "\n",
    "print(f\"SCORE Sub-Task 1: {compute_score(test_labels_hazard_category, test_labels_product_category, test_predictions_hazard_category, test_predictions_product_category):.3f}\")\n",
    "print(f\"SCORE Sub-Task 2: {compute_score(test_labels_hazard, test_labels_product, test_predictions_hazard, test_predictions_product):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81855c15-6180-4f0a-a023-8e6c5f770a26",
   "metadata": {},
   "source": [
    "## Save predictions to csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e56be26-564a-4177-926f-f640e75bd6b5",
   "metadata": {},
   "source": [
    "* Finally, I will save all the predictions from the test set into a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c16e5480-11bc-47f6-b849-14e377bc118e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hazard-category</th>\n",
       "      <th>product-category</th>\n",
       "      <th>hazard</th>\n",
       "      <th>product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>ham slices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>thermal processed pork meat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>hot dogs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biological</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>sliced ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foreign bodies</td>\n",
       "      <td>ices and desserts</td>\n",
       "      <td>metal fragment</td>\n",
       "      <td>ice cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>allergens</td>\n",
       "      <td>meat, egg and dairy products</td>\n",
       "      <td>bone fragment</td>\n",
       "      <td>chicken based products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>biological</td>\n",
       "      <td>fruits and vegetables</td>\n",
       "      <td>salmonella</td>\n",
       "      <td>dried elder berries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>biological</td>\n",
       "      <td>seafood</td>\n",
       "      <td>listeria monocytogenes</td>\n",
       "      <td>fish and fish products</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>chemical</td>\n",
       "      <td>confectionery</td>\n",
       "      <td>alkaloids</td>\n",
       "      <td>tortilla chips</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>allergens</td>\n",
       "      <td>cocoa and cocoa preparations, coffee and tea</td>\n",
       "      <td>milk and products thereof</td>\n",
       "      <td>chocolate bars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    hazard-category                              product-category  \\\n",
       "0        biological                  meat, egg and dairy products   \n",
       "1        biological                  meat, egg and dairy products   \n",
       "2        biological                  meat, egg and dairy products   \n",
       "3        biological                  meat, egg and dairy products   \n",
       "4    foreign bodies                             ices and desserts   \n",
       "..              ...                                           ...   \n",
       "992       allergens                  meat, egg and dairy products   \n",
       "993      biological                         fruits and vegetables   \n",
       "994      biological                                       seafood   \n",
       "995        chemical                                 confectionery   \n",
       "996       allergens  cocoa and cocoa preparations, coffee and tea   \n",
       "\n",
       "                        hazard                      product  \n",
       "0       listeria monocytogenes                   ham slices  \n",
       "1       listeria monocytogenes  thermal processed pork meat  \n",
       "2       listeria monocytogenes                     hot dogs  \n",
       "3       listeria monocytogenes                   sliced ham  \n",
       "4               metal fragment                    ice cream  \n",
       "..                         ...                          ...  \n",
       "992              bone fragment       chicken based products  \n",
       "993                 salmonella          dried elder berries  \n",
       "994     listeria monocytogenes       fish and fish products  \n",
       "995                  alkaloids               tortilla chips  \n",
       "996  milk and products thereof               chocolate bars  \n",
       "\n",
       "[997 rows x 4 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_set = pd.DataFrame({\n",
    "    \"hazard-category\": test_predictions_hazard_category,\n",
    "    \"product-category\": test_predictions_product_category,\n",
    "    \"hazard\": test_predictions_hazard,\n",
    "    \"product\": test_predictions_product\n",
    "})\n",
    "\n",
    "submission_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ad6a1091-547c-482b-b904-ddf5c9a62da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_set.to_csv(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf024f6-c186-4e5d-af93-24a166f1c2da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
